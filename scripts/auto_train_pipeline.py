#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Automated Training Pipeline for Video QoE Assessment
è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿ - åœ¨VMä¸­è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®å¹¶è®­ç»ƒæ¨¡å‹

This script automates the complete pipeline:
1. Run Mininet experiments to collect training data
2. Train machine learning models
3. Save pretrained models for production use

Usage:
    # å®Œæ•´æµæ°´çº¿ï¼ˆéœ€è¦çº¦2-4å°æ—¶ï¼‰
    sudo python3 scripts/auto_train_pipeline.py --samples 10 --duration 60
    
    # å¿«é€Ÿæµ‹è¯•ï¼ˆçº¦30åˆ†é’Ÿï¼‰
    sudo python3 scripts/auto_train_pipeline.py --samples 2 --duration 30 --quick
    
    # ä»…è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨å·²æœ‰æ•°æ®ï¼‰
    sudo python3 scripts/auto_train_pipeline.py --train-only

Author: Video QoE Assessment System
Date: 2025-11-15
"""

import argparse
import sys
import os
import time
import subprocess
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple

# Fix encoding issues
if sys.stdout.encoding != 'UTF-8':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Fix asyncio event loop warning
import warnings
warnings.filterwarnings('ignore', category=RuntimeWarning, message='.*coroutine.*')

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
from rich.table import Table
from rich.panel import Panel
from rich import box

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from video_qoe.experiment import ExperimentManager
from video_qoe.monitoring import RealTimePipeline
from video_qoe.utils.logger import get_logger
from video_qoe.capture import PCAPReader, PacketInfo, SlidingWindowBuffer
from video_qoe.features import FeatureCalculator
from video_qoe.output import DataWriter

console = Console()
logger = get_logger('auto_train_pipeline')

# ç½‘ç»œåœºæ™¯é…ç½®
SCENARIOS = {
    'low-bandwidth': {
        'bandwidth': 2,    # Mbps
        'latency': 100,    # ms
        'loss': 0.05,      # 5%
        'jitter': 10       # ms
    },
    'mobile-4g': {
        'bandwidth': 5,
        'latency': 50,
        'loss': 0.02,
        'jitter': 5
    },
    'wifi': {
        'bandwidth': 10,
        'latency': 30,
        'loss': 0.01,
        'jitter': 3
    },
    'high-quality': {
        'bandwidth': 20,
        'latency': 10,
        'loss': 0.001,
        'jitter': 1
    },
    'congested': {
        'bandwidth': 3,
        'latency': 150,
        'loss': 0.10,
        'jitter': 20
    },
    'stable': {
        'bandwidth': 15,
        'latency': 20,
        'loss': 0.005,
        'jitter': 2
    }
}

RESOLUTIONS = ['480p', '720p', '1080p']


def parse_arguments() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿ - è‡ªåŠ¨ç”Ÿæˆæ•°æ®å¹¶è®­ç»ƒæ¨¡å‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å®Œæ•´æµæ°´çº¿ï¼ˆæ¨èï¼‰
  sudo python3 scripts/auto_train_pipeline.py --samples 10 --duration 60
  
  # å¿«é€Ÿæµ‹è¯•
  sudo python3 scripts/auto_train_pipeline.py --samples 2 --duration 30 --quick
  
  # ä»…è®­ç»ƒï¼ˆä½¿ç”¨å·²æœ‰æ•°æ®ï¼‰
  python3 scripts/auto_train_pipeline.py --train-only
  
  # è‡ªå®šä¹‰åœºæ™¯
  sudo python3 scripts/auto_train_pipeline.py --scenarios low-bandwidth mobile-4g --samples 5
"""
    )
    
    # æ•°æ®æ”¶é›†å‚æ•°
    parser.add_argument(
        '--samples',
        type=int,
        default=10,
        help='æ¯ä¸ªåˆ†è¾¨ç‡/åœºæ™¯ç»„åˆçš„æ ·æœ¬æ•° (é»˜è®¤: 10)'
    )
    parser.add_argument(
        '--duration',
        type=int,
        default=60,
        help='æ¯ä¸ªå®éªŒçš„æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 60)'
    )
    parser.add_argument(
        '--resolutions',
        nargs='+',
        choices=RESOLUTIONS,
        default=RESOLUTIONS,
        help='è¦æµ‹è¯•çš„åˆ†è¾¨ç‡ (é»˜è®¤: å…¨éƒ¨)'
    )
    parser.add_argument(
        '--scenarios',
        nargs='+',
        choices=list(SCENARIOS.keys()),
        default=list(SCENARIOS.keys()),
        help='è¦æµ‹è¯•çš„ç½‘ç»œåœºæ™¯ (é»˜è®¤: å…¨éƒ¨)'
    )
    parser.add_argument(
        '--experiments-dir',
        type=str,
        default='experiments/',
        help='å®éªŒæ•°æ®è¾“å‡ºç›®å½• (é»˜è®¤: experiments/)'
    )
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        '--models-dir',
        type=str,
        default='models/',
        help='æ¨¡å‹è¾“å‡ºç›®å½• (é»˜è®¤: models/)'
    )
    parser.add_argument(
        '--model-types',
        nargs='+',
        choices=['xgboost', 'random_forest'],
        default=['xgboost'],
        help='è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹ (é»˜è®¤: xgboost)'
    )
    
    # æµç¨‹æ§åˆ¶
    parser.add_argument(
        '--train-only',
        action='store_true',
        help='ä»…è®­ç»ƒæ¨¡å‹ï¼ˆè·³è¿‡æ•°æ®æ”¶é›†ï¼‰'
    )
    parser.add_argument(
        '--collect-only',
        action='store_true',
        help='ä»…æ”¶é›†æ•°æ®ï¼ˆè·³è¿‡è®­ç»ƒï¼‰'
    )
    parser.add_argument(
        '--quick',
        action='store_true',
        help='å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨è¾ƒå°‘åœºæ™¯å’Œæ ·æœ¬'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ‰§è¡Œ'
    )
    
    return parser.parse_args()


def apply_quick_mode(args: argparse.Namespace) -> argparse.Namespace:
    """åº”ç”¨å¿«é€Ÿæ¨¡å¼è®¾ç½®"""
    if args.quick:
        console.print("[yellow]å¿«é€Ÿæ¨¡å¼å·²å¯ç”¨[/yellow]")
        args.samples = min(args.samples, 2)
        args.duration = min(args.duration, 30)
        args.scenarios = ['low-bandwidth', 'mobile-4g', 'wifi']
        console.print(f"  - æ ·æœ¬æ•°: {args.samples}")
        console.print(f"  - æ—¶é•¿: {args.duration}s")
        console.print(f"  - åœºæ™¯: {', '.join(args.scenarios)}")
    return args


def print_pipeline_plan(args: argparse.Namespace):
    """æ‰“å°æµæ°´çº¿è®¡åˆ’"""
    console.print(Panel.fit(
        "[bold cyan]è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿[/bold cyan]\n"
        "VMä¸­è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®å¹¶è®­ç»ƒæ¨¡å‹",
        border_style="cyan"
    ))
    
    table = Table(title="æ‰§è¡Œè®¡åˆ’", show_header=True, header_style="bold magenta", box=box.ROUNDED)
    table.add_column("é˜¶æ®µ", style="cyan", width=15)
    table.add_column("è¯¦æƒ…", style="green")
    
    if not args.train_only:
        total_experiments = len(args.resolutions) * len(args.scenarios) * args.samples
        total_time_min = (total_experiments * args.duration) / 60
        
        table.add_row(
            "1ï¸âƒ£  æ•°æ®æ”¶é›†",
            f"åˆ†è¾¨ç‡: {', '.join(args.resolutions)}\n"
            f"åœºæ™¯: {', '.join(args.scenarios)}\n"
            f"æ ·æœ¬/ç»„åˆ: {args.samples}\n"
            f"å®éªŒæ—¶é•¿: {args.duration}s\n"
            f"[bold]æ€»å®éªŒæ•°: {total_experiments}[/bold]\n"
            f"[bold]é¢„è®¡æ—¶é—´: {total_time_min:.1f} åˆ†é’Ÿ[/bold]"
        )
    
    if not args.collect_only:
        table.add_row(
            "2ï¸âƒ£  æ¨¡å‹è®­ç»ƒ",
            f"æ¨¡å‹ç±»å‹: {', '.join(args.model_types)}\n"
            f"å®éªŒç›®å½•: {args.experiments_dir}\n"
            f"æ¨¡å‹ç›®å½•: {args.models_dir}\n"
            f"[bold]é¢„è®¡æ—¶é—´: 5-15 åˆ†é’Ÿ[/bold]"
        )
    
    console.print(table)


def extract_and_save_features(context, resolution: str, logger):
    """ä»PCAPæå–ç‰¹å¾å¹¶ä¿å­˜ä¸ºfeatures.csv
    
    Args:
        context: ExperimentContextå¯¹è±¡
        resolution: å®é™…åˆ†è¾¨ç‡
        logger: æ—¥å¿—è®°å½•å™¨
    """
    pcap_path = context.pcap_path
    exp_dir = context.exp_dir
    
    console.print(f"  [dim]Reading PCAP: {pcap_path.name}...[/dim]")
    
    # è¯»å–PCAP
    reader = PCAPReader(pcap_path)
    packets = []
    
    try:
        for pkt in reader.read_all():
            try:
                packet_info = PacketInfo.from_pyshark_packet(pkt)
                if packet_info:
                    packets.append(packet_info)
            except Exception as e:
                # è·³è¿‡æ— æ³•è§£æçš„åŒ…
                continue
        
        console.print(f"  [dim]Parsed {len(packets)} packets[/dim]")
        
    except Exception as e:
        logger.warning(f"Error reading PCAP: {e}")
        console.print(f"  [yellow]âš  PCAP read error: {e}[/yellow]")
    
    if not packets:
        logger.warning("No valid packets found in PCAP")
        console.print(f"  [yellow]âš  No valid packets, skipping feature extraction[/yellow]")
        return
    
    # æå–ç‰¹å¾
    console.print(f"  [dim]Extracting features...[/dim]")
    window = SlidingWindowBuffer(window_size=1.0)
    calculator = FeatureCalculator()
    data_writer = DataWriter(exp_dir, logger=logger)
    
    feature_count = 0
    for pkt in packets:
        window.add_packet(pkt)
        
        if window.should_process():
            window_packets = window.get_window_packets()
            if window_packets:
                try:
                    features = calculator.compute_all_features(window_packets, client_ip=context.client_ip)
                    
                    # åˆ›å»ºè™šæ‹Ÿé¢„æµ‹ï¼ˆå› ä¸ºè¿™æ˜¯è®­ç»ƒæ•°æ®ï¼‰
                    from video_qoe.prediction.predictor import Prediction
                    prediction = Prediction(
                        resolution=resolution,  # ä½¿ç”¨å®é™…åˆ†è¾¨ç‡
                        confidence=1.0,
                        method='ground_truth'
                    )
                    
                    # ä¿å­˜ç‰¹å¾
                    data_writer.append_data(
                        elapsed=pkt.timestamp - packets[0].timestamp,
                        prediction=prediction,
                        features=features
                    )
                    feature_count += 1
                    
                except Exception as e:
                    logger.debug(f"Error computing features: {e}")
                    continue
    
    # å®Œæˆ
    data_writer.finalize()
    console.print(f"  [dim]Saved {feature_count} feature samples[/dim]")


def run_single_experiment(resolution: str, scenario: str, scenario_config: Dict,
                         duration: int, experiment_dir: Path, run_id: int) -> bool:
    """è¿è¡Œå•ä¸ªMininetå®éªŒæ”¶é›†æ•°æ®
    
    Args:
        resolution: ç›®æ ‡åˆ†è¾¨ç‡
        scenario: åœºæ™¯åç§°
        scenario_config: ç½‘ç»œé…ç½®
        duration: å®éªŒæ—¶é•¿
        experiment_dir: å®éªŒè¾“å‡ºç›®å½•
        run_id: è¿è¡ŒID
        
    Returns:
        Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
    """
    try:
        console.print(f"Starting experiment: {resolution} - {scenario} (run {run_id})")
        
        # åˆ›å»ºå®éªŒç®¡ç†å™¨
        exp_manager = ExperimentManager(logger=logger)
        
        # è®¾ç½®å®éªŒï¼ˆä¼šè‡ªåŠ¨é…ç½®ç½‘ç»œæ¡ä»¶ï¼‰
        context = exp_manager.setup_experiment(
            scenario_name=scenario
        )
        
        # è®°å½•ç›®æ ‡åˆ†è¾¨ç‡åˆ°Ground Truth
        if exp_manager.ground_truth:
            exp_manager.ground_truth.video.actual_resolution = resolution
            console.print(f"Ground truth resolution set to: {resolution}")
        
        if not context:
            logger.error("Failed to setup experiment")
            return False
        
        # è·å–èŠ‚ç‚¹
        h2 = exp_manager.h2
        h1 = exp_manager.h1
        
        # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
        video_dir = '/home/mininet/cn/video'
        video_file = f'video_{resolution}.mp4'
        video_path = f'{video_dir}/{video_file}'
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        check_result = h1.cmd(f'ls {video_path} 2>/dev/null')
        
        if check_result.strip():
            # ä½¿ç”¨çœŸå®è§†é¢‘æ–‡ä»¶
            download_file = video_file
            console.print(f"âœ“ Using video: {video_path} for {resolution}")
        else:
            # å¤‡ç”¨ï¼šåˆ›å»ºæµ‹è¯•æ–‡ä»¶
            logger.warning(f"Video file not found: {video_path}")
            console.print("Creating fallback test file...")
            h1.cmd('mkdir -p /tmp/webserver')
            h1.cmd('dd if=/dev/zero of=/tmp/webserver/test.dat bs=1M count=2 2>/dev/null')
            video_dir = '/tmp/webserver'
            download_file = 'test.dat'
            console.print(f"Using fallback: {video_dir}/{download_file}")
        
        # åˆ›å»ºå®æ—¶ç›‘æµ‹æµæ°´çº¿
        pipeline = RealTimePipeline(
            interface=context.capture_interface,
            pcap_path=str(context.pcap_path),
            client_ip=context.client_ip,
            node=h2,
            window_size=1.0,
            predictor_type='rule_based',
            output_color=False,
            capture_mode=True
        )
        
        # è¿è¡Œæµæ°´çº¿å¹¶ç”Ÿæˆæµé‡
        with pipeline:
            # å¯åŠ¨æŒç»­è§†é¢‘ä¸‹è½½ï¼ˆåå°ï¼‰
            console.print(f"Starting video downloads: {download_file}")
            
            # å¯åŠ¨å¤šä¸ªå¹¶å‘ä¸‹è½½ä»¥ç”ŸæˆçœŸå®æµé‡
            for i in range(3):
                h2.cmd(f'while true; do curl -s http://{context.server_ip}:{context.server_port}/{download_file} > /dev/null 2>&1; sleep 0.3; done &')
            
            # ç­‰å¾…æµé‡ç¨³å®š
            time.sleep(2)
            console.print("Traffic generation started, monitoring...")
            
            # è¿è¡Œç›‘æµ‹
            stats = pipeline.run(duration=duration)
        
        # æ¸…ç†å®éªŒ
        exp_manager.cleanup()
        
        console.print(f"Experiment completed: {stats.predictions_made} predictions")
        
        # NOTE: è·³è¿‡å®æ—¶ç‰¹å¾æå–ä»¥åŠ å¿«æ•°æ®æ”¶é›†
        # ç‰¹å¾å°†åœ¨è®­ç»ƒé˜¶æ®µç»Ÿä¸€ä»PCAPæå–
        console.print("[dim]PCAP saved, features will be extracted during training[/dim]")
        
        return True
        
    except Exception as e:
        logger.error(f"Experiment failed: {e}")
        try:
            exp_manager.cleanup()
        except:
            pass
        return False


def collect_training_data(args: argparse.Namespace) -> Tuple[bool, int, int]:
    """æ”¶é›†è®­ç»ƒæ•°æ®
    
    Returns:
        (success, total, failed) - æˆåŠŸæ ‡å¿—ã€æ€»æ•°ã€å¤±è´¥æ•°
    """
    console.print("\n" + "=" * 80)
    console.print("[bold cyan]é˜¶æ®µ 1/2: æ”¶é›†è®­ç»ƒæ•°æ®[/bold cyan]")
    console.print("=" * 80 + "\n")
    
    experiment_dir = Path(args.experiments_dir)
    experiment_dir.mkdir(parents=True, exist_ok=True)
    
    total_experiments = len(args.resolutions) * len(args.scenarios) * args.samples
    successful = 0
    failed = 0
    
    console.print(f"å°†è¿è¡Œ {total_experiments} ä¸ªå®éªŒ...\n")
    
    if args.dry_run:
        console.print("[yellow]æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - è·³è¿‡å®é™…æ‰§è¡Œ[/yellow]\n")
        return True, total_experiments, 0
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console
    ) as progress:
        task = progress.add_task("æ‰§è¡Œå®éªŒä¸­", total=total_experiments)
        
        for resolution in args.resolutions:
            for scenario in args.scenarios:
                scenario_config = SCENARIOS[scenario]
                
                console.print(f"\n[cyan]ğŸ“Š {resolution} - {scenario}[/cyan]")
                console.print(f"   ç½‘ç»œ: BW={scenario_config['bandwidth']}Mbps, "
                            f"å»¶è¿Ÿ={scenario_config['latency']}ms, "
                            f"ä¸¢åŒ…={scenario_config['loss']*100:.1f}%")
                
                for run_id in range(1, args.samples + 1):
                    try:
                        success = run_single_experiment(
                            resolution, scenario, scenario_config,
                            args.duration, experiment_dir, run_id
                        )
                        
                        if success:
                            successful += 1
                            console.print(f"   âœ“ è¿è¡Œ {run_id}/{args.samples} æˆåŠŸ")
                        else:
                            failed += 1
                            console.print(f"   âœ— è¿è¡Œ {run_id}/{args.samples} å¤±è´¥")
                            
                    except KeyboardInterrupt:
                        console.print("\n[yellow]ç”¨æˆ·ä¸­æ–­[/yellow]")
                        raise
                    except Exception as e:
                        console.print(f"   âœ— è¿è¡Œ {run_id}/{args.samples} é”™è¯¯: {e}")
                        failed += 1
                    
                    progress.update(task, advance=1)
                    
                    # å®éªŒé—´çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(2)
    
    # æ‰“å°æ±‡æ€»
    console.print("\n" + "=" * 80)
    console.print("[bold]æ•°æ®æ”¶é›†æ±‡æ€»[/bold]")
    console.print("=" * 80)
    console.print(f"æ€»å®éªŒæ•°: {total_experiments}")
    console.print(f"[green]æˆåŠŸ: {successful}[/green]")
    if failed > 0:
        console.print(f"[red]å¤±è´¥: {failed}[/red]")
    console.print(f"è¾“å‡ºç›®å½•: {experiment_dir}")
    console.print("=" * 80)
    
    return failed == 0, total_experiments, failed


def train_models(args: argparse.Namespace) -> bool:
    """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹
    
    Returns:
        Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
    """
    console.print("\n" + "=" * 80)
    console.print("[bold cyan]é˜¶æ®µ 2/2: è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹[/bold cyan]")
    console.print("=" * 80 + "\n")
    
    if args.dry_run:
        console.print("[yellow]æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - è·³è¿‡å®é™…æ‰§è¡Œ[/yellow]\n")
        return True
    
    # é¦–å…ˆæ‰¹é‡æå–ç‰¹å¾
    console.print("[cyan]æ­¥éª¤ 2.1: ä»PCAPæ‰¹é‡æå–ç‰¹å¾[/cyan]\n")
    extract_cmd = [
        sys.executable,
        'scripts/extract_features_from_pcap.py',
        '--experiments-dir', args.experiments_dir
    ]
    
    try:
        result = subprocess.run(extract_cmd, cwd=project_root, check=True)
        console.print("[green]âœ“ ç‰¹å¾æå–å®Œæˆ[/green]\n")
    except subprocess.CalledProcessError:
        console.print("[yellow]âš  ç‰¹å¾æå–å¤±è´¥ï¼Œå°†å°è¯•ç»§ç»­è®­ç»ƒ[/yellow]\n")
    except FileNotFoundError:
        console.print("[yellow]âš  ç‰¹å¾æå–è„šæœ¬æœªæ‰¾åˆ°ï¼Œè·³è¿‡[/yellow]\n")
    
    console.print("[cyan]æ­¥éª¤ 2.2: è®­ç»ƒæ¨¡å‹[/cyan]\n")
    
    models_dir = Path(args.models_dir)
    models_dir.mkdir(parents=True, exist_ok=True)
    
    all_success = True
    
    for model_type in args.model_types:
        console.print(f"\n[cyan]ğŸ¤– è®­ç»ƒ {model_type} æ¨¡å‹...[/cyan]\n")
        
        try:
            # æ„å»ºè®­ç»ƒå‘½ä»¤
            cmd = [
                sys.executable,
                'scripts/train_model.py',
                '--experiments-dir', args.experiments_dir,
                '--output-dir', args.models_dir,
                '--model-type', model_type,
                '--class-names', '480p', '720p', '1080p'
            ]
            
            # æ‰§è¡Œè®­ç»ƒ
            result = subprocess.run(
                cmd,
                cwd=project_root,
                capture_output=False,
                text=True
            )
            
            if result.returncode == 0:
                console.print(f"[green]âœ“ {model_type} æ¨¡å‹è®­ç»ƒæˆåŠŸ[/green]")
            else:
                console.print(f"[red]âœ— {model_type} æ¨¡å‹è®­ç»ƒå¤±è´¥[/red]")
                all_success = False
                
        except Exception as e:
            console.print(f"[red]âœ— {model_type} æ¨¡å‹è®­ç»ƒé”™è¯¯: {e}[/red]")
            all_success = False
    
    return all_success


def save_pipeline_metadata(args: argparse.Namespace, data_success: bool, 
                          train_success: bool, duration: float):
    """ä¿å­˜æµæ°´çº¿å…ƒæ•°æ®"""
    metadata = {
        'pipeline_version': '1.0.0',
        'timestamp': datetime.now().isoformat(),
        'duration_seconds': duration,
        'configuration': {
            'samples': args.samples,
            'experiment_duration': args.duration,
            'resolutions': args.resolutions,
            'scenarios': args.scenarios,
            'model_types': args.model_types,
        },
        'results': {
            'data_collection_success': data_success,
            'training_success': train_success,
        },
        'output': {
            'experiments_dir': args.experiments_dir,
            'models_dir': args.models_dir,
        }
    }
    
    metadata_path = Path(args.models_dir) / 'pipeline_metadata.json'
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    console.print(f"\n[dim]å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}[/dim]")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    args = apply_quick_mode(args)
    
    # æ‰“å°è®¡åˆ’
    print_pipeline_plan(args)
    
    # ç¡®è®¤
    if not args.dry_run:
        console.print("\n[yellow]æ­¤æµæ°´çº¿å°†å ç”¨å¤§é‡æ—¶é—´å’Œèµ„æº[/yellow]")
        if not args.train_only:
            console.print("[yellow]éœ€è¦ sudo æƒé™è¿è¡Œ Mininet å®éªŒ[/yellow]")
        response = input("\nç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            console.print("[yellow]å·²å–æ¶ˆ[/yellow]")
            return 0
    
    start_time = time.time()
    
    # æ‰§è¡Œæµæ°´çº¿
    data_success = True
    train_success = True
    
    try:
        # é˜¶æ®µ1: æ”¶é›†æ•°æ®
        if not args.train_only:
            data_success, total, failed = collect_training_data(args)
            
            if not data_success:
                console.print("\n[red]âš  æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­æœ‰å¤±è´¥çš„å®éªŒ[/red]")
                if failed > total * 0.3:  # è¶…è¿‡30%å¤±è´¥
                    console.print("[red]å¤±è´¥ç‡è¿‡é«˜ï¼Œå»ºè®®æ£€æŸ¥åé‡è¯•[/red]")
                    if not args.collect_only:
                        response = input("æ˜¯å¦ç»§ç»­è®­ç»ƒæ¨¡å‹? (y/n): ")
                        if response.lower() != 'y':
                            return 1
        
        # é˜¶æ®µ2: è®­ç»ƒæ¨¡å‹
        if not args.collect_only:
            train_success = train_models(args)
        
        duration = time.time() - start_time
        
        # ä¿å­˜å…ƒæ•°æ®
        if not args.dry_run:
            save_pipeline_metadata(args, data_success, train_success, duration)
        
        # æœ€ç»ˆæ±‡æ€»
        console.print("\n" + "=" * 80)
        console.print("[bold]ğŸ‰ æµæ°´çº¿æ‰§è¡Œå®Œæˆ[/bold]")
        console.print("=" * 80)
        console.print(f"æ€»è€—æ—¶: {duration/60:.1f} åˆ†é’Ÿ")
        
        if not args.train_only:
            console.print(f"å®éªŒæ•°æ®: {args.experiments_dir}")
        
        if not args.collect_only:
            console.print(f"è®­ç»ƒæ¨¡å‹: {args.models_dir}")
            console.print("\n[cyan]ğŸ“¦ å¯ç”¨æ¨¡å‹:[/cyan]")
            models_dir = Path(args.models_dir)
            for model_file in models_dir.glob('*.pkl'):
                if 'preprocessor' not in model_file.name:
                    console.print(f"  - {model_file.name}")
        
        console.print("\n[bold green]âœ“ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼[/bold green]")
        console.print("\n[cyan]ä¸‹ä¸€æ­¥:[/cyan]")
        console.print("  1. åœ¨å®¿ä¸»æœºä¸Šä½¿ç”¨æ¨¡å‹:")
        console.print("     python scripts/realtime_capture_host.py --model models/xgboost_model.pkl")
        console.print("\n  2. æµ‹è¯•æ¨¡å‹å‡†ç¡®æ€§:")
        console.print("     python scripts/test_model.py --model models/xgboost_model.pkl")
        
        return 0 if (data_success and train_success) else 1
        
    except KeyboardInterrupt:
        console.print("\n[yellow]æµæ°´çº¿è¢«ç”¨æˆ·ä¸­æ–­[/yellow]")
        return 130
    except Exception as e:
        console.print(f"\n[red]æµæ°´çº¿æ‰§è¡Œé”™è¯¯: {e}[/red]")
        logger.exception("Pipeline execution error")
        return 1


if __name__ == '__main__':
    sys.exit(main())

