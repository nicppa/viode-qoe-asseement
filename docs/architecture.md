# ç³»ç»Ÿæ¶æ„æ–‡æ¡£
## è§†é¢‘è´¨é‡è¯„ä¼°ç³»ç»Ÿ - Mininetç‰ˆ

**é¡¹ç›®åç§°ï¼š** åº”ç”¨è´¨é‡è¯„ä¼°  
**ç‰ˆæœ¬ï¼š** 1.0 (MVP)  
**æ—¥æœŸï¼š** 2025-11-08  
**æ¶æ„å¸ˆï¼š** BMad  
**çŠ¶æ€ï¼š** âœ… å·²å®Œæˆ

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰äº†"è§†é¢‘è´¨é‡è¯„ä¼°ç³»ç»Ÿ"çš„å®Œæ•´æŠ€æœ¯æ¶æ„ï¼ŒåŒ…æ‹¬ç³»ç»Ÿè®¾è®¡ã€æ¨¡å—åˆ’åˆ†ã€å…³é”®æŠ€æœ¯é€‰å‹ã€æ•°æ®æµè®¾è®¡å’ŒV2æ‰©å±•è§„åˆ’ã€‚

**æ¶æ„ç›®æ ‡ï¼š**
- âœ… æ»¡è¶³å®æ—¶ç›‘æµ‹è¦æ±‚ï¼ˆå»¶è¿Ÿ < 10ç§’ï¼‰
- âœ… å‡†ç¡®è®¡ç®—35ä¸ªç‰¹å¾ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
- âœ… æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæµ‹è¯•å’Œç»´æŠ¤
- âœ… ä¸ºV2çœŸå®æµè§ˆå™¨åœºæ™¯é¢„ç•™æ‰©å±•ç‚¹

**ç›¸å…³æ–‡æ¡£ï¼š**
- [PRDäº§å“éœ€æ±‚æ–‡æ¡£](PRD.md) - åŠŸèƒ½éœ€æ±‚å®šä¹‰
- [å¤´è„‘é£æš´ä¼šè¯](brainstorming-session-2025-11-08.md) - åˆ›æ–°ç‰¹å¾å·¥ç¨‹æ–¹æ³•
- [é¢†åŸŸç ”ç©¶æŠ¥å‘Š](research-comprehensive-2025-11-08.md) - æŠ€æœ¯è°ƒç ”

---

## ğŸ¯ æ¶æ„è®¾è®¡åŸåˆ™

### æ ¸å¿ƒåŸåˆ™

1. **å®æ—¶æ€§ä¼˜å…ˆ**ï¼šæµå¼å¤„ç†ï¼Œè¾¹æ•è·è¾¹åˆ†æï¼Œä¸ç­‰å®Œæ•´PCAP
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šåŸç”ŸPython + numpyå‘é‡åŒ–ï¼Œç¡®ä¿ < 10ç§’å»¶è¿Ÿ
3. **æ¨¡å—è§£è€¦**ï¼š7å¤§æ ¸å¿ƒæ¨¡å—ï¼Œç‹¬ç«‹å¼€å‘æµ‹è¯•
4. **é…ç½®é©±åŠ¨**ï¼šåœºæ™¯ã€æ¨¡å‹ã€è¾“å‡ºå¯çµæ´»é…ç½®
5. **å¯æ‰©å±•æ€§**ï¼šæ¥å£æŠ½è±¡ï¼Œä¸ºV2çœŸå®æµè§ˆå™¨é¢„ç•™æ‰©å±•ç‚¹
6. **ç ”ç©¶å‹å¥½**ï¼šä»£ç å¯è¯»æ€§ä¸æ€§èƒ½å¹³è¡¡ï¼Œä¾¿äºè®ºæ–‡å¤ç°

### è®¾è®¡çº¦æŸ

**æ€§èƒ½çº¦æŸï¼š**
- ç›‘æµ‹å»¶è¿Ÿ < 10ç§’ï¼ˆç«¯åˆ°ç«¯ï¼‰
- å†…å­˜å ç”¨ < 2GB
- CPUä½¿ç”¨ < 50%ï¼ˆå•æ ¸ï¼‰
- å¯åŠ¨æ—¶é—´ < 30ç§’

**åŠŸèƒ½çº¦æŸï¼š**
- MVPä»…æ”¯æŒMininetç¯å¢ƒ
- å•æœºè¿è¡Œï¼ˆéåˆ†å¸ƒå¼ï¼‰
- å•æµé‡æ•è·ï¼ˆä¸€æ¬¡ä¸€ä¸ªå®éªŒï¼‰

**æŠ€æœ¯çº¦æŸï¼š**
- Python 3.8+
- Mininet 2.3+
- Linuxç¯å¢ƒï¼ˆUbuntu 20.04+ï¼‰
- éœ€è¦rootæƒé™ï¼ˆç½‘ç»œæ•è·ï¼‰

---

## ğŸ—ï¸ ç³»ç»Ÿæ•´ä½“æ¶æ„

### æ¶æ„æ¨¡å¼

é‡‡ç”¨ **Pipelineæ¶æ„æ¨¡å¼**ï¼ˆæµæ°´çº¿å¤„ç†ï¼‰+ **åˆ†å±‚æ¶æ„**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·æ¥å£å±‚                                 â”‚
â”‚              CLIå‘½ä»¤è¡Œ (monitor.py / train_model.py)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨é€»è¾‘å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ å®éªŒç®¡ç†å™¨    â”‚  â”‚ ç›‘æµ‹æµæ°´çº¿    â”‚  â”‚ è®­ç»ƒæµæ°´çº¿    â”‚     â”‚
â”‚  â”‚ (Experiment  â”‚  â”‚ (Monitoring  â”‚  â”‚ (Training    â”‚     â”‚
â”‚  â”‚  Manager)    â”‚  â”‚  Pipeline)   â”‚  â”‚  Pipeline)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ ¸å¿ƒæœåŠ¡å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ æµé‡æ•è·    â”‚  â”‚ ç‰¹å¾æå–    â”‚  â”‚ é¢„æµ‹å¼•æ“    â”‚           â”‚
â”‚  â”‚ (Capturer) â”‚â†’â”‚ (Feature   â”‚â†’â”‚ (Predictor)â”‚           â”‚
â”‚  â”‚            â”‚  â”‚  Extractor)â”‚  â”‚            â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ æ¨¡å‹è®­ç»ƒ    â”‚  â”‚ è¾“å‡ºç®¡ç†    â”‚  â”‚ é…ç½®ç®¡ç†    â”‚           â”‚
â”‚  â”‚ (Trainer)  â”‚  â”‚ (Output)   â”‚  â”‚ (Config)   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åŸºç¡€è®¾æ–½å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Mininet    â”‚  â”‚ tcpdump/   â”‚  â”‚ æ–‡ä»¶ç³»ç»Ÿ    â”‚           â”‚
â”‚  â”‚ ç½‘ç»œä»¿çœŸ    â”‚  â”‚ pyshark    â”‚  â”‚ PCAP/CSV   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµæ¶æ„

**å®æ—¶ç›‘æµ‹æ•°æ®æµï¼š**

```
1. å®éªŒå¯åŠ¨
   â†“
2. Mininetç¯å¢ƒåˆå§‹åŒ–
   â”œâ”€ åˆ›å»ºç½‘ç»œæ‹“æ‰‘ (h1 â†â†’ s1 â†â†’ h2)
   â”œâ”€ é…ç½®ç½‘ç»œæ¡ä»¶ (å¸¦å®½/å»¶è¿Ÿ/ä¸¢åŒ…)
   â””â”€ å¯åŠ¨HTTP Server (h1)
   â†“
3. æµé‡æ•è·å¯åŠ¨
   â”œâ”€ tcpdumpåå°æ•è· â†’ capture.pcap
   â””â”€ pysharkå®æ—¶è¯»å–
   â†“
4. å®æ—¶å¤„ç†æµæ°´çº¿ (æ¯ç§’å¾ªç¯)
   â”œâ”€ åŒ…é¢„å¤„ç†: Packet â†’ PacketInfo (è½»é‡çº§)
   â”œâ”€ æ»‘åŠ¨çª—å£: ç»´æŠ¤æœ€è¿‘1ç§’çš„æ•°æ®åŒ…
   â”œâ”€ ç‰¹å¾è®¡ç®—: 35ä¸ªç‰¹å¾ (numpyå‘é‡åŒ–)
   â”œâ”€ æ¨¡å‹æ¨ç†: XGBoosté¢„æµ‹åˆ†è¾¨ç‡
   â””â”€ è¾“å‡ºæ˜¾ç¤º: CLIå®æ—¶è¾“å‡º + CSVå†™å…¥
   â†“
5. å®éªŒç»“æŸ
   â”œâ”€ ä¿å­˜å®Œæ•´PCAP
   â”œâ”€ ä¿å­˜ç‰¹å¾CSV
   â”œâ”€ ä¿å­˜Ground Truth
   â””â”€ ç”Ÿæˆå®éªŒæŠ¥å‘Š
```

**æ¨¡å‹è®­ç»ƒæ•°æ®æµï¼š**

```
1. åŠ è½½å®éªŒæ•°æ®
   â”œâ”€ æ‰«æexperiments/ç›®å½•
   â”œâ”€ åŠ è½½PCAPæ–‡ä»¶
   â””â”€ åŠ è½½Ground Truth
   â†“
2. æ‰¹é‡ç‰¹å¾æå–
   â”œâ”€ éå†PCAP (ç¦»çº¿åˆ†æ)
   â”œâ”€ è®¡ç®—35ä¸ªç‰¹å¾ (å¤ç”¨ç›‘æµ‹ä»£ç )
   â””â”€ ç”Ÿæˆå®Œæ•´ç‰¹å¾DataFrame
   â†“
3. æ•°æ®é¢„å¤„ç†
   â”œâ”€ ç¼ºå¤±å€¼å¤„ç†
   â”œâ”€ ç‰¹å¾å½’ä¸€åŒ–
   â”œâ”€ ç‰¹å¾é€‰æ‹© (å¯é€‰)
   â””â”€ åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
   â†“
4. æ¨¡å‹è®­ç»ƒ
   â”œâ”€ è®­ç»ƒXGBoost
   â”œâ”€ è®­ç»ƒRandom Forest
   â”œâ”€ è®­ç»ƒLSTM
   â””â”€ è¶…å‚æ•°è°ƒä¼˜
   â†“
5. æ¨¡å‹è¯„ä¼°
   â”œâ”€ å‡†ç¡®ç‡/ç²¾ç¡®ç‡/å¬å›ç‡
   â”œâ”€ æ··æ·†çŸ©é˜µ
   â”œâ”€ ç‰¹å¾é‡è¦æ€§åˆ†æ
   â””â”€ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
   â†“
6. ä¿å­˜æ¨¡å‹
   â””â”€ åºåˆ—åŒ–ä¸º.pklæ–‡ä»¶
```

---

## ğŸ§© æ ¸å¿ƒæ¨¡å—è®¾è®¡

### æ¨¡å—1: å®éªŒç®¡ç†å™¨ (ExperimentManager)

**èŒè´£ï¼š**
- è§£æå‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®æ–‡ä»¶
- åˆå§‹åŒ–Mininetç¯å¢ƒ
- åè°ƒå„æ¨¡å—çš„å¯åŠ¨å’Œåœæ­¢
- ç”Ÿæˆå®éªŒIDå’Œç›®å½•ç»“æ„
- è®°å½•Ground Truth

**å…³é”®ç»„ä»¶ï¼š**

```python
class ExperimentManager:
    """å®éªŒç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.exp_id = self._generate_exp_id()
        self.exp_dir = Path('experiments') / self.exp_id
        self.mininet_topo = None
        self.ground_truth = GroundTruth()
    
    def setup(self) -> ExperimentContext:
        """å®éªŒç¯å¢ƒå‡†å¤‡"""
        # 1. åˆ›å»ºå®éªŒç›®å½•
        self.exp_dir.mkdir(parents=True, exist_ok=True)
        
        # 2. ä¿å­˜é…ç½®
        self._save_config()
        
        # 3. åˆå§‹åŒ–Mininet
        self.mininet_topo = self._setup_mininet()
        
        # 4. è®°å½•Ground Truth
        self.ground_truth.record_config(self.config)
        
        return ExperimentContext(
            exp_id=self.exp_id,
            exp_dir=self.exp_dir,
            capture_interface='h2-eth0',
            pcap_path=self.exp_dir / 'capture.pcap'
        )
    
    def _setup_mininet(self) -> Mininet:
        """Mininetæ‹“æ‰‘åˆå§‹åŒ–"""
        # åˆ›å»ºæ‹“æ‰‘: h1 (server) â†â†’ s1 â†â†’ h2 (client)
        topo = SingleSwitchTopo(n=2)
        net = Mininet(topo=topo, link=TCLink, controller=OVSController)
        net.start()
        
        # è·å–ä¸»æœº
        h1, h2 = net.get('h1', 'h2')
        
        # é…ç½®ç½‘ç»œæ¡ä»¶ï¼ˆåœ¨h2çš„linkä¸Šï¼‰
        self._configure_network_conditions(net, h2)
        
        # å¯åŠ¨HTTP Serverï¼ˆh1ï¼‰
        self._start_http_server(h1)
        
        return net
    
    def _configure_network_conditions(self, net, host):
        """é…ç½®å¸¦å®½ã€å»¶è¿Ÿã€ä¸¢åŒ…"""
        link = net.linksBetween(net.get('s1'), host)[0]
        link.intf1.config(
            bw=self._parse_bandwidth(self.config.network.bandwidth),
            delay=self.config.network.delay,
            loss=self.config.network.loss,
            jitter=self.config.network.jitter
        )
        
        # è®°å½•åˆ°Ground Truth
        self.ground_truth.record_network_config(self.config.network)
    
    def cleanup(self):
        """æ¸…ç†å®éªŒç¯å¢ƒ"""
        if self.mininet_topo:
            self.mininet_topo.stop()
        
        # ä¿å­˜Ground Truth
        self.ground_truth.save(self.exp_dir / 'ground_truth.json')
```

**æ¥å£å®šä¹‰ï¼š**

```python
@dataclass
class ExperimentConfig:
    """å®éªŒé…ç½®"""
    experiment: Dict  # name, description
    network: NetworkConfig  # bandwidth, delay, loss, jitter
    video: VideoConfig  # file, expected_resolution
    model: ModelConfig  # path, confidence_threshold
    monitoring: MonitoringConfig  # update_interval, enable_color
    output: OutputConfig  # save_pcap, save_features

@dataclass
class ExperimentContext:
    """å®éªŒè¿è¡Œä¸Šä¸‹æ–‡"""
    exp_id: str
    exp_dir: Path
    capture_interface: str
    pcap_path: Path
```

---

### æ¨¡å—2: æµé‡æ•è·å™¨ (PacketCapturer)

**èŒè´£ï¼š**
- ä½¿ç”¨tcpdumpåå°æ•è·PCAP
- ä½¿ç”¨pysharkå®æ—¶è¯»å–æµå¼æ•°æ®åŒ…
- åŒæ—¶ä¿å­˜å®Œæ•´PCAPæ–‡ä»¶ç”¨äºç¦»çº¿åˆ†æ

**æŠ€æœ¯é€‰å‹ï¼š** tcpdump + pysharkè¯»å–ï¼ˆç¨³å®šå¯é ï¼‰

**è®¾è®¡ï¼š**

```python
class PacketCapturer:
    """æµé‡æ•è·å™¨ï¼ˆtcpdump + pysharkï¼‰"""
    
    def __init__(self, interface: str, pcap_path: Path):
        self.interface = interface
        self.pcap_path = pcap_path
        self.tcpdump_process = None
        self.capture = None
    
    def start(self):
        """å¯åŠ¨æ•è·"""
        # 1. å¯åŠ¨tcpdumpåå°è¿›ç¨‹ï¼ˆä¿å­˜PCAPï¼‰
        self.tcpdump_process = subprocess.Popen([
            'sudo', 'tcpdump',
            '-i', self.interface,
            '-w', str(self.pcap_path),
            '-s', '0',  # å®Œæ•´åŒ…
            'tcp'  # åªæ•è·TCP
        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # 2. ç­‰å¾…PCAPæ–‡ä»¶åˆ›å»º
        time.sleep(1)
        
        # 3. å¯åŠ¨pysharkå®æ—¶è¯»å–
        self.capture = pyshark.FileCapture(
            str(self.pcap_path),
            keep_packets=False,  # ä¸ä¿ç•™åœ¨å†…å­˜ï¼ˆé‡è¦ï¼ï¼‰
            display_filter='tcp'
        )
    
    def get_packet_stream(self) -> Iterator[Packet]:
        """è·å–å®æ—¶æ•°æ®åŒ…æµ"""
        return self.capture.sniff_continuously()
    
    def stop(self):
        """åœæ­¢æ•è·"""
        if self.tcpdump_process:
            self.tcpdump_process.terminate()
            self.tcpdump_process.wait()
        
        if self.capture:
            self.capture.close()
```

**å…³é”®è®¾è®¡ç‚¹ï¼š**
- `keep_packets=False`: pysharkä¸åœ¨å†…å­˜ä¸­ä¿ç•™æ•°æ®åŒ…ï¼Œé¿å…å†…å­˜æ³„æ¼
- `sniff_continuously()`: æµå¼è¿­ä»£å™¨ï¼Œè¾¹è¯»è¾¹å¤„ç†
- tcpdumpåœ¨åå°æŒç»­å†™å…¥ï¼Œpysharkå®æ—¶å°¾éšè¯»å–

---

### æ¨¡å—3: ç‰¹å¾æå–å¼•æ“ (FeatureExtractor)

**èŒè´£ï¼š**
- ç»´æŠ¤1ç§’æ»‘åŠ¨çª—å£
- è®¡ç®—35ä¸ªTCP/IPç‰¹å¾ï¼ˆæ€§èƒ½ä¼˜åŒ–é‡ç‚¹ï¼‰
- è¾“å‡ºç‰¹å¾å‘é‡ä¾›æ¨¡å‹ä½¿ç”¨

**æŠ€æœ¯é€‰å‹ï¼š** åŸç”ŸPython + numpyå‘é‡åŒ–ï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰

**ä¸‰å±‚æ¶æ„ï¼š**

#### å±‚1: åŒ…çº§é¢„å¤„ç†

```python
@dataclass
class PacketInfo:
    """è½»é‡çº§æ•°æ®åŒ…ä¿¡æ¯ï¼ˆé¿å…ä¿ç•™å®Œæ•´åŒ…å¯¹è±¡ï¼‰"""
    timestamp: float
    size: int
    tcp_seq: Optional[int]
    tcp_ack: Optional[int]
    tcp_flags: Optional[str]
    tcp_window: Optional[int]
    rtt: Optional[float]
    is_retrans: bool
    direction: str  # 'up' or 'down'

class PacketPreprocessor:
    """åŒ…é¢„å¤„ç†å™¨"""
    
    def __init__(self, client_ip: str):
        self.client_ip = client_ip
    
    def extract_packet_info(self, pkt) -> Optional[PacketInfo]:
        """ä»pyshark Packetæå–å…³é”®ä¿¡æ¯"""
        try:
            # åªå¤„ç†TCPåŒ…
            if not hasattr(pkt, 'tcp'):
                return None
            
            # æå–å…³é”®å­—æ®µ
            return PacketInfo(
                timestamp=float(pkt.sniff_timestamp),
                size=int(pkt.length),
                tcp_seq=int(pkt.tcp.seq) if hasattr(pkt.tcp, 'seq') else None,
                tcp_ack=int(pkt.tcp.ack) if hasattr(pkt.tcp, 'ack') else None,
                tcp_flags=pkt.tcp.flags if hasattr(pkt.tcp, 'flags') else None,
                tcp_window=int(pkt.tcp.window_size_value) if hasattr(pkt.tcp, 'window_size_value') else None,
                rtt=float(pkt.tcp.analysis.ack_rtt) if hasattr(pkt.tcp, 'analysis') and hasattr(pkt.tcp.analysis, 'ack_rtt') else None,
                is_retrans=(hasattr(pkt.tcp, 'analysis') and hasattr(pkt.tcp.analysis, 'retransmission')),
                direction='up' if pkt.ip.src == self.client_ip else 'down'
            )
        except Exception as e:
            logger.warning(f"Failed to extract packet info: {e}")
            return None
```

#### å±‚2: æ»‘åŠ¨çª—å£ç¼“å†²

```python
class SlidingWindowBuffer:
    """1ç§’æ»‘åŠ¨çª—å£ï¼ˆé«˜æ•ˆå®ç°ï¼‰"""
    
    def __init__(self, window_size: float = 1.0):
        self.packets = deque()  # åŒç«¯é˜Ÿåˆ—ï¼ŒO(1)æ’å…¥åˆ é™¤
        self.window_size = window_size
    
    def add_packet(self, pkt_info: PacketInfo):
        """æ·»åŠ æ•°æ®åŒ…"""
        self.packets.append(pkt_info)
        self._cleanup_old_packets()
    
    def _cleanup_old_packets(self):
        """ç§»é™¤çª—å£å¤–çš„è€æ•°æ®åŒ…"""
        if not self.packets:
            return
        
        now = self.packets[-1].timestamp
        while self.packets and (now - self.packets[0].timestamp) > self.window_size:
            self.packets.popleft()
    
    def get_window_data(self) -> List[PacketInfo]:
        """è·å–å½“å‰çª—å£çš„æ‰€æœ‰æ•°æ®åŒ…"""
        return list(self.packets)
    
    def is_ready(self) -> bool:
        """çª—å£æ˜¯å¦å·²ç§¯ç´¯è¶³å¤Ÿæ•°æ®"""
        if len(self.packets) < 10:  # è‡³å°‘10ä¸ªåŒ…
            return False
        
        if not self.packets:
            return False
        
        duration = self.packets[-1].timestamp - self.packets[0].timestamp
        return duration >= self.window_size * 0.8  # è‡³å°‘0.8ç§’
```

#### å±‚3: é«˜æ€§èƒ½ç‰¹å¾è®¡ç®—

```python
class OptimizedFeatureCalculator:
    """35ä¸ªç‰¹å¾çš„é«˜æ€§èƒ½è®¡ç®—ï¼ˆåŸç”ŸPython + numpyï¼‰"""
    
    def compute_all_features(self, packets: List[PacketInfo]) -> np.ndarray:
        """
        è®¡ç®—35ä¸ªç‰¹å¾
        æ€§èƒ½ç›®æ ‡: < 3ç§’ï¼ˆ1ç§’çª—å£æ•°æ®ï¼‰
        """
        if not packets:
            return np.zeros(35)
        
        # ä¸€æ¬¡æ€§è½¬numpyæ•°ç»„ï¼ˆåç»­æ‰€æœ‰è®¡ç®—å¤ç”¨ï¼‰
        timestamps = np.array([p.timestamp for p in packets])
        sizes = np.array([p.size for p in packets])
        rtts = np.array([p.rtt for p in packets if p.rtt is not None])
        windows = np.array([p.tcp_window for p in packets if p.tcp_window is not None])
        
        # å¹¶è¡Œè®¡ç®—ä¸‰ç»„ç‰¹å¾
        tcp_features = self._compute_tcp_features(packets, rtts, windows)
        traffic_features = self._compute_traffic_features(packets, timestamps, sizes)
        temporal_features = self._compute_temporal_features(timestamps, sizes)
        
        return np.concatenate([tcp_features, traffic_features, temporal_features])
    
    def _compute_tcp_features(self, packets, rtts, windows) -> np.ndarray:
        """TCPå±‚ç‰¹å¾ï¼ˆ10ä¸ªï¼‰"""
        features = np.zeros(10)
        
        # 1. é‡ä¼ ç‡
        retrans_count = sum(1 for p in packets if p.is_retrans)
        features[0] = retrans_count / len(packets) if packets else 0
        
        # 2-4. RTTç»Ÿè®¡ï¼ˆnumpyå‘é‡åŒ–ï¼‰
        if len(rtts) > 0:
            features[1] = np.mean(rtts)  # avg_rtt
            features[2] = np.std(rtts)   # rtt_std
            features[3] = np.max(rtts)   # max_rtt
        
        # 5-6. TCPçª—å£ç»Ÿè®¡
        if len(windows) > 0:
            features[4] = np.mean(windows)  # avg_window
            features[5] = np.var(windows)   # window_var
        
        # 7. æ…¢å¯åŠ¨è®¡æ•°ï¼ˆçª—å£å¿«é€Ÿå¢é•¿ï¼‰
        features[6] = self._detect_slow_start(windows)
        
        # 8. æ‹¥å¡äº‹ä»¶ï¼ˆçª—å£çªé™ï¼‰
        features[7] = self._detect_congestion_events(windows)
        
        # 9. ACKå»¶è¿Ÿ
        features[8] = self._compute_ack_delay(packets)
        
        # 10. è¿æ¥å»ºç«‹æ—¶é—´
        features[9] = self._get_conn_setup_time(packets)
        
        return features
    
    def _compute_traffic_features(self, packets, timestamps, sizes) -> np.ndarray:
        """æµé‡ç»Ÿè®¡ç‰¹å¾ï¼ˆ15ä¸ªï¼‰"""
        features = np.zeros(15)
        
        # ååé‡è®¡ç®—ï¼ˆå‘é‡åŒ–ï¼‰
        if len(timestamps) > 1:
            duration = timestamps[-1] - timestamps[0]
            if duration > 0:
                total_bytes = np.sum(sizes)
                throughput_mbps = (total_bytes * 8) / (duration * 1e6)
                
                # ç»†ç²’åº¦ååé‡ï¼ˆ10ä¸ª100msçª—å£ï¼‰
                mini_windows = np.array_split(sizes, 10)
                mini_throughputs = [
                    np.sum(w) * 8 / 0.1 / 1e6 
                    for w in mini_windows if len(w) > 0
                ]
                
                features[0] = throughput_mbps  # avg_throughput
                if mini_throughputs:
                    features[1] = np.std(mini_throughputs)   # throughput_std
                    features[2] = np.min(mini_throughputs)   # throughput_min
                    features[3] = np.max(mini_throughputs)   # throughput_max
                    mean_tp = np.mean(mini_throughputs)
                    features[4] = np.std(mini_throughputs) / mean_tp if mean_tp > 0 else 0  # throughput_cv
        
        # åŒ…å¤§å°ç»Ÿè®¡
        features[5] = np.mean(sizes)              # avg_packet_size
        features[6] = np.std(sizes)               # packet_size_std
        features[7] = np.sum(sizes > 1200) / len(sizes)  # large_packet_ratio (MTU)
        features[8] = self._compute_entropy(sizes)       # packet_size_entropy
        
        # ä¸Šä¸‹è¡Œæ¯”ä¾‹
        up_bytes = sum(p.size for p in packets if p.direction == 'up')
        down_bytes = sum(p.size for p in packets if p.direction == 'down')
        features[9] = up_bytes / down_bytes if down_bytes > 0 else 0
        
        # æ€»é‡ç»Ÿè®¡
        features[10] = np.sum(sizes)                    # total_bytes
        features[11] = len(sizes)                       # total_packets
        features[12] = timestamps[-1] - timestamps[0]   # conn_duration
        features[13] = np.var(np.diff(sizes)) if len(sizes) > 1 else 0  # byte_rate_var
        features[14] = 1  # flow_count (Mininetå•æµ)
        
        return features
    
    def _compute_temporal_features(self, timestamps, sizes) -> np.ndarray:
        """æ—¶åºç‰¹å¾ï¼ˆ10ä¸ªï¼‰"""
        features = np.zeros(10)
        
        # åŒ…é—´éš”ç»Ÿè®¡
        if len(timestamps) > 1:
            intervals = np.diff(timestamps)
            features[0] = np.mean(intervals)  # interval_mean
            features[1] = np.std(intervals)   # interval_std
            mean_iv = np.mean(intervals)
            features[2] = np.std(intervals) / mean_iv if mean_iv > 0 else 0  # interval_cv
        else:
            intervals = np.array([])
        
        # å‘¨æœŸæ€§æ£€æµ‹ï¼ˆFFTï¼‰
        features[3] = self._compute_periodicity_fft(intervals)
        
        # ç©ºçª—æœŸæ£€æµ‹
        if len(intervals) > 0:
            gap_threshold = 0.5  # 500ms
            gaps = intervals > gap_threshold
            features[4] = np.sum(gaps)  # num_gaps
            features[5] = np.mean(intervals[gaps]) if np.sum(gaps) > 0 else 0  # gap_duration_avg
        
        # çªå‘æ£€æµ‹
        features[6], features[7] = self._detect_bursts(timestamps, sizes)
        
        # è‡ªç›¸å…³
        features[8] = self._compute_autocorrelation(sizes)
        
        # è¶‹åŠ¿æ–œç‡
        features[9] = self._compute_trend_slope(timestamps, sizes)
        
        return features
    
    # è¾…åŠ©æ–¹æ³•
    def _compute_entropy(self, values: np.ndarray) -> float:
        """è®¡ç®—é¦™å†œç†µ"""
        hist, _ = np.histogram(values, bins=20)
        prob = hist / np.sum(hist)
        prob = prob[prob > 0]
        return -np.sum(prob * np.log2(prob))
    
    def _compute_periodicity_fft(self, intervals: np.ndarray) -> float:
        """FFTæ£€æµ‹å‘¨æœŸæ€§"""
        if len(intervals) < 4:
            return 0
        fft = np.fft.fft(intervals)
        power = np.abs(fft) ** 2
        return np.max(power[1:]) / np.sum(power) if np.sum(power) > 0 else 0
    
    def _detect_bursts(self, timestamps, sizes) -> Tuple[int, float]:
        """çªå‘æ£€æµ‹ï¼ˆæ»‘åŠ¨çª—å£ï¼‰"""
        burst_threshold = np.mean(sizes) * 2
        burst_count = 0
        burst_intensity = 0
        
        # 100msæ»‘åŠ¨çª—å£
        window_size = 0.1
        i = 0
        while i < len(timestamps):
            window_start = timestamps[i]
            window_bytes = 0
            j = i
            while j < len(timestamps) and (timestamps[j] - window_start) < window_size:
                window_bytes += sizes[j]
                j += 1
            
            if window_bytes > burst_threshold:
                burst_count += 1
                burst_intensity += window_bytes
            
            i = j if j > i else i + 1
        
        return burst_count, burst_intensity / burst_count if burst_count > 0 else 0
    
    def _compute_autocorrelation(self, values: np.ndarray, lag: int = 1) -> float:
        """è‡ªç›¸å…³ç³»æ•°"""
        if len(values) < lag + 1:
            return 0
        return np.corrcoef(values[:-lag], values[lag:])[0, 1] if len(values) > lag else 0
    
    def _compute_trend_slope(self, timestamps, sizes) -> float:
        """çº¿æ€§æ‹Ÿåˆè¶‹åŠ¿"""
        if len(timestamps) < 2:
            return 0
        coeffs = np.polyfit(timestamps - timestamps[0], sizes, 1)
        return coeffs[0]  # æ–œç‡
    
    def _detect_slow_start(self, windows: np.ndarray) -> int:
        """æ£€æµ‹æ…¢å¯åŠ¨ï¼ˆçª—å£æŒ‡æ•°å¢é•¿ï¼‰"""
        if len(windows) < 3:
            return 0
        
        growth_rate = np.diff(windows) / (windows[:-1] + 1)
        return np.sum(growth_rate > 0.5)  # å¢é•¿50%ä»¥ä¸Š
    
    def _detect_congestion_events(self, windows: np.ndarray) -> int:
        """æ£€æµ‹æ‹¥å¡äº‹ä»¶ï¼ˆçª—å£çªé™ï¼‰"""
        if len(windows) < 2:
            return 0
        
        drop_rate = np.diff(windows) / (windows[:-1] + 1)
        return np.sum(drop_rate < -0.5)  # ä¸‹é™50%ä»¥ä¸Š
    
    def _compute_ack_delay(self, packets: List[PacketInfo]) -> float:
        """å¹³å‡ACKå»¶è¿Ÿ"""
        ack_packets = [p for p in packets if p.tcp_flags and 'A' in p.tcp_flags]
        if not ack_packets or len(ack_packets) < 2:
            return 0
        
        timestamps = np.array([p.timestamp for p in ack_packets])
        delays = np.diff(timestamps)
        return np.mean(delays)
    
    def _get_conn_setup_time(self, packets: List[PacketInfo]) -> float:
        """è¿æ¥å»ºç«‹æ—¶é—´ï¼ˆSYN â†’ SYN-ACK â†’ ACKï¼‰"""
        # æŸ¥æ‰¾SYN, SYN-ACK, ACK
        syn_time = None
        synack_time = None
        
        for p in packets:
            if not p.tcp_flags:
                continue
            if 'S' in p.tcp_flags and 'A' not in p.tcp_flags:  # SYN
                syn_time = p.timestamp
            elif 'S' in p.tcp_flags and 'A' in p.tcp_flags:  # SYN-ACK
                synack_time = p.timestamp
            elif syn_time and synack_time and 'A' in p.tcp_flags:  # ACK
                return p.timestamp - syn_time
        
        return synack_time - syn_time if (syn_time and synack_time) else 0
```

**æ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹ï¼š**
1. âœ… å•æ¬¡éå†ï¼šæ•°æ®è½¬numpyåï¼Œæ‰€æœ‰è®¡ç®—åŸºäºå‘é‡æ“ä½œ
2. âœ… è½»é‡çº§å¯¹è±¡ï¼šPacketInfoåªä¿ç•™å¿…è¦å­—æ®µ
3. âœ… é¿å…Pythonå¾ªç¯ï¼šå°½å¯èƒ½ä½¿ç”¨numpyå‡½æ•°
4. âœ… å¢é‡è®¡ç®—ï¼šæ»‘åŠ¨çª—å£dequeé«˜æ•ˆ
5. âœ… é¢„ä¼°æ€§èƒ½ï¼š2-3ç§’ï¼ˆ1ç§’çª—å£æ•°æ®ï¼‰

---

### æ¨¡å—4: é¢„æµ‹å¼•æ“ (PredictionEngine)

**èŒè´£ï¼š**
- åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
- ç‰¹å¾å‘é‡ â†’ åˆ†è¾¨ç‡é¢„æµ‹
- è®¡ç®—ç½®ä¿¡åº¦

**è®¾è®¡ï¼š**

```python
@dataclass
class Prediction:
    """é¢„æµ‹ç»“æœ"""
    resolution: str  # '480p', '720p', '1080p'
    confidence: float  # 0-1
    probabilities: np.ndarray  # [prob_480p, prob_720p, prob_1080p]
    timestamp: float

class PredictionEngine:
    """é¢„æµ‹å¼•æ“ï¼ˆå•ä¾‹æ¨¡å‹ï¼‰"""
    
    def __init__(self, model_path: Path):
        self.model = self._load_model(model_path)
        self.classes = ['480p', '720p', '1080p']
    
    def _load_model(self, model_path: Path):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        if not model_path.exists():
            raise FileNotFoundError(f"Model not found: {model_path}")
        
        return joblib.load(model_path)
    
    def predict(self, features: np.ndarray) -> Prediction:
        """
        é¢„æµ‹åˆ†è¾¨ç‡
        Args:
            features: shape (1, 35) æˆ– (35,)
        Returns:
            Predictionå¯¹è±¡
        """
        # ç¡®ä¿shapeæ­£ç¡®
        if features.ndim == 1:
            features = features.reshape(1, -1)
        
        # æ¨¡å‹æ¨ç†
        probabilities = self.model.predict_proba(features)[0]
        pred_class = np.argmax(probabilities)
        
        return Prediction(
            resolution=self.classes[pred_class],
            confidence=probabilities[pred_class],
            probabilities=probabilities,
            timestamp=time.time()
        )
    
    def batch_predict(self, features: np.ndarray) -> List[Prediction]:
        """æ‰¹é‡é¢„æµ‹ï¼ˆç”¨äºç¦»çº¿åˆ†æï¼‰"""
        probabilities = self.model.predict_proba(features)
        pred_classes = np.argmax(probabilities, axis=1)
        
        return [
            Prediction(
                resolution=self.classes[pred_classes[i]],
                confidence=probabilities[i, pred_classes[i]],
                probabilities=probabilities[i],
                timestamp=time.time()
            )
            for i in range(len(features))
        ]
```

---

### æ¨¡å—5: è¾“å‡ºç®¡ç†å™¨ (OutputManager)

**èŒè´£ï¼š**
- CLIå®æ—¶è¾“å‡ºï¼ˆrichåº“ï¼Œé¢œè‰²é«˜äº®ï¼‰
- æ•°æ®æŒä¹…åŒ–ï¼ˆCSVã€JSONã€PCAPï¼‰
- å®éªŒæ€»ç»“æŠ¥å‘Š

**æŠ€æœ¯é€‰å‹ï¼š** richåº“ï¼ˆç°ä»£åŒ–CLIä½“éªŒï¼‰

**è®¾è®¡ï¼š**

```python
class OutputManager:
    """è¾“å‡ºç®¡ç†å™¨"""
    
    def __init__(self, exp_dir: Path, enable_color: bool = True):
        self.exp_dir = exp_dir
        self.cli_writer = CLIWriter(enable_color)
        self.data_writer = DataWriter(exp_dir)
        self.start_time = time.time()
        self.event_count = {'quality_up': 0, 'quality_down': 0, 'stall': 0}
    
    def output_realtime(self, prediction: Prediction, metrics: NetworkMetrics):
        """å®æ—¶è¾“å‡ºï¼ˆæ¯ç§’è°ƒç”¨ä¸€æ¬¡ï¼‰"""
        # 1. CLIè¾“å‡º
        elapsed = int(time.time() - self.start_time)
        self.cli_writer.write_line(elapsed, prediction, metrics)
        
        # 2. åŒæ­¥å†™å…¥CSV
        self.data_writer.append_csv(elapsed, prediction, metrics)
        
        # 3. æ£€æµ‹äº‹ä»¶
        self._detect_and_log_events(prediction, metrics)
    
    def finalize(self):
        """å®éªŒç»“æŸï¼Œç”Ÿæˆæ€»ç»“"""
        self.data_writer.close()
        self._generate_summary()

class CLIWriter:
    """CLIè¾“å‡ºï¼ˆrichåº“ï¼‰"""
    
    def __init__(self, enable_color: bool):
        self.console = Console() if enable_color else Console(no_color=True)
        self.prev_resolution = None
    
    def write_header(self, exp_id: str, scenario: str, video: str):
        """è¾“å‡ºå¤´éƒ¨ä¿¡æ¯"""
        self.console.print("\n[bold]=== è§†é¢‘è´¨é‡å®æ—¶ç›‘æµ‹ ===[/bold]")
        self.console.print(f"å®éªŒID: {exp_id}")
        self.console.print(f"åœºæ™¯: {scenario}")
        self.console.print(f"è§†é¢‘: {video}")
        self.console.print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.console.print("â”" * 80)
        self.console.print()
    
    def write_line(self, elapsed: int, prediction: Prediction, metrics: NetworkMetrics):
        """è¾“å‡ºå•è¡Œç›‘æµ‹æ•°æ®"""
        # æ ¼å¼åŒ–æ—¶é—´
        time_str = f"[{elapsed:03d}]"
        
        # åˆ†è¾¨ç‡ï¼ˆé¢œè‰²ç¼–ç ï¼‰
        res_str = self._format_resolution(prediction.resolution, prediction.confidence)
        
        # ç½‘ç»œæŒ‡æ ‡
        metrics_str = (
            f"ååé‡: {metrics.throughput:.1f} Mbps | "
            f"ä¸¢åŒ…: {metrics.loss_rate:.1f}% | "
            f"RTT: {metrics.rtt:.0f}ms"
        )
        
        # äº‹ä»¶æ ‡æ³¨
        event_str = self._check_events(prediction)
        
        # ç»„åˆè¾“å‡º
        line = f"{time_str} {res_str} | {metrics_str}{event_str}"
        self.console.print(line)
    
    def _format_resolution(self, resolution: str, confidence: float) -> str:
        """åˆ†è¾¨ç‡é¢œè‰²ç¼–ç """
        conf_str = f"({confidence*100:.0f}%)"
        
        # ä½ç½®ä¿¡åº¦è­¦å‘Š
        if confidence < 0.7:
            return f"[yellow]{resolution}? {conf_str}[/yellow]"
        
        # æ­£å¸¸ç½®ä¿¡åº¦ï¼ŒæŒ‰åˆ†è¾¨ç‡ç€è‰²
        color_map = {
            '480p': 'red',
            '720p': 'yellow',
            '1080p': 'green',
            '4K': 'bright_green'
        }
        color = color_map.get(resolution, 'white')
        return f"[{color}]{resolution} {conf_str}[/{color}]"
    
    def _check_events(self, prediction: Prediction) -> str:
        """æ£€æµ‹è´¨é‡å˜åŒ–äº‹ä»¶"""
        if self.prev_resolution is None:
            self.prev_resolution = prediction.resolution
            return ""
        
        event = ""
        if prediction.resolution != self.prev_resolution:
            if self._resolution_to_num(prediction.resolution) > self._resolution_to_num(self.prev_resolution):
                event = " [green]âš ï¸ è´¨é‡æå‡[/green]"
            else:
                event = " [red]ğŸ”´ è´¨é‡ä¸‹é™[/red]"
        
        self.prev_resolution = prediction.resolution
        return event
    
    @staticmethod
    def _resolution_to_num(res: str) -> int:
        """åˆ†è¾¨ç‡è½¬æ•°å­—"""
        return {'480p': 1, '720p': 2, '1080p': 3, '4K': 4}.get(res, 0)

class DataWriter:
    """æ•°æ®æŒä¹…åŒ–"""
    
    def __init__(self, exp_dir: Path):
        self.exp_dir = exp_dir
        self.features_csv = exp_dir / 'features.csv'
        self.timeline_json = exp_dir / 'timeline.json'
        
        # åˆå§‹åŒ–CSV
        self.csv_file = open(self.features_csv, 'w', newline='')
        self.csv_writer = csv.writer(self.csv_file)
        self._write_csv_header()
        
        # æ—¶é—´çº¿æ•°æ®
        self.timeline_events = []
    
    def _write_csv_header(self):
        """å†™å…¥CSVè¡¨å¤´ï¼ˆ35ä¸ªç‰¹å¾ + é¢„æµ‹ + ç½®ä¿¡åº¦ï¼‰"""
        headers = [
            'timestamp',
            # TCPç‰¹å¾ï¼ˆ10ä¸ªï¼‰
            'retrans_rate', 'avg_rtt', 'rtt_std', 'max_rtt', 'avg_window', 
            'window_var', 'slow_start_count', 'congestion_events', 'ack_delay', 'conn_setup_time',
            # æµé‡ç»Ÿè®¡ç‰¹å¾ï¼ˆ15ä¸ªï¼‰
            'avg_throughput', 'throughput_std', 'throughput_min', 'throughput_max', 'throughput_cv',
            'avg_packet_size', 'packet_size_std', 'large_packet_ratio', 'packet_size_entropy',
            'uplink_downlink_ratio', 'total_bytes', 'total_packets', 'conn_duration', 'byte_rate_var', 'flow_count',
            # æ—¶åºç‰¹å¾ï¼ˆ10ä¸ªï¼‰
            'interval_mean', 'interval_std', 'interval_cv', 'periodicity_score', 'num_gaps',
            'gap_duration_avg', 'burst_count', 'burst_intensity', 'autocorrelation', 'trend_slope',
            # é¢„æµ‹ç»“æœ
            'predicted_resolution', 'confidence'
        ]
        self.csv_writer.writerow(headers)
    
    def append_csv(self, elapsed: int, prediction: Prediction, metrics: NetworkMetrics):
        """è¿½åŠ ä¸€è¡Œæ•°æ®ï¼ˆç‰¹å¾ + é¢„æµ‹ï¼‰"""
        # è¿™é‡Œfeatureså·²ç»åœ¨å‰é¢è®¡ç®—è¿‡ï¼Œéœ€è¦ä¼ å…¥
        # ç®€åŒ–èµ·è§ï¼Œä»metricsä¸­æå–
        row = [elapsed] + list(metrics.features) + [prediction.resolution, prediction.confidence]
        self.csv_writer.writerow(row)
        self.csv_file.flush()  # ç«‹å³å†™å…¥
    
    def close(self):
        """å…³é—­æ–‡ä»¶"""
        if self.csv_file:
            self.csv_file.close()
```

---

## â±ï¸ æ€§èƒ½åˆ†æ

### å»¶è¿Ÿåˆ†è§£

| é˜¶æ®µ | é¢„ä¼°å»¶è¿Ÿ | è¯´æ˜ | ä¼˜åŒ–æªæ–½ |
|-----|---------|------|---------|
| PCAPæ•è· | 1-2ç§’ | tcpdumpå†™å…¥å»¶è¿Ÿ | åå°å¼‚æ­¥ï¼Œæ— æ³•é¿å… |
| åŒ…è§£æ | 0.5ç§’ | pysharkè¯»å–1ç§’çª—å£ | æµå¼è¯»å–ï¼Œå·²ä¼˜åŒ– |
| **ç‰¹å¾è®¡ç®—** | **2-3ç§’** | **35ä¸ªç‰¹å¾è®¡ç®—ï¼ˆå…³é”®è·¯å¾„ï¼‰** | **numpyå‘é‡åŒ–ï¼Œå•æ¬¡éå†** |
| æ¨¡å‹æ¨ç† | 0.1ç§’ | XGBoost C++åç«¯ | å·²æœ€ä¼˜ |
| CLIè¾“å‡º | 0.1ç§’ | richè¾“å‡º | å¼‚æ­¥å†™å…¥ |
| **æ€»å»¶è¿Ÿ** | **4-7ç§’** | **âœ… æ»¡è¶³<10ç§’è¦æ±‚** | - |

### å†…å­˜å ç”¨

| ç»„ä»¶ | é¢„ä¼°å†…å­˜ | è¯´æ˜ |
|-----|---------|------|
| Mininet | ~200MB | ç½‘ç»œä»¿çœŸ |
| tcpdump | ~50MB | PCAPæ•è· |
| pyshark | ~100MB | åŒ…è§£æ |
| æ»‘åŠ¨çª—å£ | ~10MB | 1ç§’è½»é‡çº§PacketInfo |
| æ¨¡å‹ | ~50MB | XGBoostæ¨¡å‹ |
| Pythonè¿è¡Œæ—¶ | ~100MB | åŸºç¡€å¼€é”€ |
| **æ€»è®¡** | **~500MB-1GB** | **âœ… è¿œå°äº2GBé™åˆ¶** |

### CPUä½¿ç”¨

- **æ­£å¸¸è´Ÿè½½ï¼š** 30-40%ï¼ˆå•æ ¸ï¼‰
- **å³°å€¼è´Ÿè½½ï¼š** 50-60%ï¼ˆç‰¹å¾è®¡ç®—æ—¶ï¼‰
- **ç©ºé—²æœŸï¼š** <10%ï¼ˆç­‰å¾…æ•°æ®åŒ…ï¼‰

### æ‰©å±•æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¦‚éœ€ï¼‰

å¦‚æœå®é™…æµ‹è¯•å‘ç°å»¶è¿Ÿ>7ç§’ï¼Œå¯é‡‡ç”¨ï¼š

1. **å¤šçº¿ç¨‹æµæ°´çº¿ï¼š**
   ```
   çº¿ç¨‹1: æ•è· + è§£æ
   çº¿ç¨‹2: ç‰¹å¾è®¡ç®—
   çº¿ç¨‹3: æ¨¡å‹æ¨ç† + è¾“å‡º
   ```

2. **Cythonç¼–è¯‘çƒ­ç‚¹ï¼š**
   - å°†`_compute_tcp_features`ç­‰ç¼–è¯‘ä¸ºCæ‰©å±•
   - é¢„è®¡æé€Ÿ2-3å€

3. **æ›´æ¿€è¿›çš„å¢é‡è®¡ç®—ï¼š**
   - ç¼“å­˜ä¸Šä¸€ç§’çš„ä¸­é—´ç»“æœ
   - åªè®¡ç®—å¢é‡å˜åŒ–

---

## ğŸ“Š æ¨¡å‹è®­ç»ƒæ¡†æ¶æ¶æ„

### è®¾è®¡åŸåˆ™

**è®­ç»ƒä¸ç›‘æµ‹è§£è€¦ï¼Œä½†å…±äº«ç‰¹å¾è®¡ç®—æ ¸å¿ƒ**

```
ç›‘æµ‹å·¥å…· (monitor.py)       è®­ç»ƒæ¡†æ¶ (train_model.py)
      â†“                              â†“
  å®æ—¶ç‰¹å¾æå–                  æ‰¹é‡ç‰¹å¾æå–
      â†“                              â†“
      â””â”€â”€â”€â”€â”€â”€â”€â”€â†’  å…±äº«ç‰¹å¾åº“  â†â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           (video_qoe.features)
```

### è®­ç»ƒæµæ°´çº¿

```python
class ModelTrainingPipeline:
    """ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹"""
    
    def __init__(self, config: TrainingConfig):
        self.data_loader = ExperimentDataLoader()
        self.feature_extractor = FeatureExtractor()  # å¤ç”¨ç›‘æµ‹ä»£ç 
        self.preprocessor = FeaturePreprocessor()
        self.trainer = ModelTrainer()
        self.evaluator = ModelEvaluator()
    
    def run(self, experiments_dir: Path, output_dir: Path):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        # 1. åŠ è½½æ‰€æœ‰å®éªŒ
        logger.info("Loading experiments...")
        experiments = self.data_loader.load_experiments(experiments_dir)
        logger.info(f"Found {len(experiments)} experiments")
        
        # 2. æ‰¹é‡ç‰¹å¾æå–
        logger.info("Extracting features...")
        features_df = self._batch_extract_features(experiments)
        
        # 3. æ•°æ®é¢„å¤„ç†
        logger.info("Preprocessing...")
        X, y = self.preprocessor.prepare_dataset(features_df)
        
        # 4. åˆ’åˆ†æ•°æ®é›†
        X_train, X_val, X_test, y_train, y_val, y_test = \
            self._split_dataset(X, y)
        
        # 5. è®­ç»ƒå¤šç§æ¨¡å‹
        logger.info("Training models...")
        models = {}
        for model_type in ['xgboost', 'random_forest', 'lstm']:
            logger.info(f"  Training {model_type}...")
            model = self.trainer.train(
                model_type, X_train, y_train, X_val, y_val
            )
            models[model_type] = model
        
        # 6. è¯„ä¼°å¯¹æ¯”
        logger.info("Evaluating models...")
        results = self.evaluator.evaluate_all(models, X_test, y_test)
        
        # 7. ä¿å­˜æœ€ä½³æ¨¡å‹
        best_model_name = max(results, key=lambda x: results[x]['accuracy'])
        best_model = models[best_model_name]
        model_path = output_dir / f'{best_model_name}_v1.0.pkl'
        joblib.dump(best_model, model_path)
        logger.info(f"Best model ({best_model_name}) saved to {model_path}")
        
        # 8. ä¿å­˜é¢„å¤„ç†å™¨
        self.preprocessor.save(output_dir / 'preprocessor_v1.0.pkl')
        
        # 9. ç”ŸæˆæŠ¥å‘Š
        self.evaluator.generate_report(results, output_dir)
        logger.info(f"Evaluation report saved to {output_dir}/evaluation_report.md")
```

---

## ğŸ“ é¡¹ç›®ä»£ç ç»“æ„

```
video-qoe-assessment/
â”œâ”€â”€ video_qoe/                      # æ ¸å¿ƒåº“ï¼ˆpipå®‰è£…åŒ…ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ features/                   # ç‰¹å¾è®¡ç®—ï¼ˆå…±äº«æ ¸å¿ƒï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extractor.py           # ç»Ÿä¸€æ¥å£
â”‚   â”‚   â”œâ”€â”€ tcp_features.py        # TCPè®¡ç®—å™¨
â”‚   â”‚   â”œâ”€â”€ traffic_features.py    # æµé‡è®¡ç®—å™¨
â”‚   â”‚   â”œâ”€â”€ temporal_features.py   # æ—¶åºè®¡ç®—å™¨
â”‚   â”‚   â””â”€â”€ packet_info.py         # PacketInfoç±»
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/                 # å®æ—¶ç›‘æµ‹
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ capturer.py
â”‚   â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â”‚   â”œâ”€â”€ window_buffer.py
â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                   # æ¨¡å‹è®­ç»ƒ
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ experiment/                 # å®éªŒç®¡ç†
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â”œâ”€â”€ topology.py
â”‚   â”‚   â””â”€â”€ scenarios.py
â”‚   â”‚
â”‚   â”œâ”€â”€ output/                     # è¾“å‡ºç®¡ç†
â”‚   â”‚   â”œâ”€â”€ cli_writer.py
â”‚   â”‚   â””â”€â”€ data_writer.py
â”‚   â”‚
â”‚   â””â”€â”€ models/                     # æ¨¡å‹ç›¸å…³
â”‚       â”œâ”€â”€ base.py
â”‚       â””â”€â”€ model_loader.py
â”‚
â”œâ”€â”€ scripts/                        # CLIå·¥å…·
â”‚   â”œâ”€â”€ monitor.py                 # å®æ—¶ç›‘æµ‹
â”‚   â”œâ”€â”€ train_model.py             # æ¨¡å‹è®­ç»ƒ
â”‚   â””â”€â”€ extract_features.py        # ç‰¹å¾æå–
â”‚
â”œâ”€â”€ configs/                        # é…ç½®
â”‚   â”œâ”€â”€ scenarios/                 # åœºæ™¯æ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ low-bandwidth.yaml
â”‚   â”‚   â”œâ”€â”€ high-quality.yaml
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ default_config.yaml
â”‚
â”œâ”€â”€ models/                         # é¢„è®­ç»ƒæ¨¡å‹
â”‚   â”œâ”€â”€ xgboost_v1.0.pkl
â”‚   â””â”€â”€ preprocessor_v1.0.pkl
â”‚
â”œâ”€â”€ experiments/                    # å®éªŒæ•°æ®
â”œâ”€â”€ tests/                          # å•å…ƒæµ‹è¯•
â”œâ”€â”€ docs/                           # æ–‡æ¡£
â””â”€â”€ README.md
```

---

## âš™ï¸ é…ç½®ç®¡ç†

### å¤šå±‚é…ç½®ç³»ç»Ÿ

**ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š**
1. å‘½ä»¤è¡Œå‚æ•°
2. ç”¨æˆ·é…ç½®æ–‡ä»¶ï¼ˆ`--config`ï¼‰
3. åœºæ™¯æ¨¡æ¿ï¼ˆ`--scenario`ï¼‰
4. é»˜è®¤é…ç½®

### åœºæ™¯æ¨¡æ¿ç¤ºä¾‹

```yaml
# configs/scenarios/low-bandwidth.yaml
name: "Low Bandwidth Scenario"
network:
  bandwidth: 2 Mbps
  delay: 50 ms
  loss: 1%
video:
  expected_resolution: "720p"
monitoring:
  update_interval: 1
  confidence_threshold: 0.7
```

---

## ğŸ”Œ V2æ‰©å±•ç‚¹è®¾è®¡

### ä¸ºçœŸå®æµè§ˆå™¨åœºæ™¯é¢„ç•™æ¥å£

#### 1. æµé‡æ¥æºæŠ½è±¡

```python
class ITrafficSource(ABC):
    @abstractmethod
    def start_capture(self, interface: str) -> None: pass
    
    @abstractmethod
    def get_packet_stream(self) -> Iterator[Packet]: pass

# MVP: MininetTrafficSource
# V2: BrowserTrafficSource (withæµé‡è¿‡æ»¤)
```

#### 2. æµé‡è¯†åˆ«æ¨¡å—ï¼ˆV2æ–°å¢ï¼‰

```python
class VideoTrafficClassifier:
    def is_video_flow(self, flow: Flow) -> bool:
        """åˆ¤æ–­æ˜¯å¦è§†é¢‘æµé‡"""
        pass
    
    def identify_platform(self, flow: Flow) -> str:
        """è¯†åˆ«å¹³å°ï¼ˆYouTube/Netflix/çˆ±å¥‡è‰ºï¼‰"""
        pass
```

#### 3. å¯æ’æ‹”ç‰¹å¾è®¡ç®—å™¨

```python
class IFeatureCalculator(ABC):
    @abstractmethod
    def compute(self, packets) -> np.ndarray: pass

# å…è®¸ç ”ç©¶äººå‘˜æ‰©å±•æ–°ç‰¹å¾
```

---

## ğŸ“Š å…³é”®æ¶æ„å†³ç­–è®°å½•

| å†³ç­–ç‚¹ | é€‰æ‹© | ç†ç”± | æƒè¡¡ |
|-------|------|------|------|
| **æµé‡æ•è·** | tcpdump + pyshark | ç¨³å®šå¯é  | ç•¥æœ‰å»¶è¿Ÿä½†å¯æ¥å— |
| **ç‰¹å¾è®¡ç®—** | åŸç”ŸPython + numpy | æ€§èƒ½ä¼˜å…ˆ | ä»£ç å¤æ‚åº¦ â†‘ |
| **æ¨¡å‹ç®¡ç†** | å•ä¾‹æ¨¡å‹ | MVPç®€æ´ | V2éœ€æ‰©å±• |
| **CLIè¾“å‡º** | rich | ç°ä»£ä½“éªŒ | ä¾èµ– â†‘ |
| **ä»£ç å¤ç”¨** | å…±äº«ç‰¹å¾åº“ | é¿å…é‡å¤ | æ¥å£è®¾è®¡ |

---

## âœ… æ¶æ„éªŒè¯

### æ»¡è¶³çš„PRDéœ€æ±‚

**æ€§èƒ½éœ€æ±‚ï¼š**
- âœ… ç›‘æµ‹å»¶è¿Ÿ 4-7ç§’ < 10ç§’è¦æ±‚
- âœ… å†…å­˜å ç”¨ ~1GB < 2GBé™åˆ¶
- âœ… CPUä½¿ç”¨ 30-50% < 50%è¦æ±‚
- âœ… å¯åŠ¨æ—¶é—´ < 30ç§’ï¼ˆMininetå¯åŠ¨ï¼‰

**åŠŸèƒ½éœ€æ±‚ï¼š**
- âœ… 7å¤§æ ¸å¿ƒæ¨¡å—èŒè´£æ¸…æ™°
- âœ… 35ä¸ªç‰¹å¾å‡†ç¡®è®¡ç®—ï¼ˆnumpyä¼˜åŒ–ï¼‰
- âœ… å®æ—¶ç›‘æµ‹ + æ¨¡å‹è®­ç»ƒåŒæµæ°´çº¿
- âœ… é…ç½®é©±åŠ¨ï¼ˆåœºæ™¯æ¨¡æ¿ï¼‰
- âœ… V2æ‰©å±•ç‚¹é¢„ç•™

**éåŠŸèƒ½éœ€æ±‚ï¼š**
- âœ… æ¨¡å—è§£è€¦ï¼Œä¾¿äºæµ‹è¯•
- âœ… æ¥å£æŠ½è±¡ï¼Œæ˜“äºæ‰©å±•
- âœ… ä»£ç å¤ç”¨ï¼ˆå…±äº«ç‰¹å¾åº“ï¼‰
- âœ… å¯è§‚æµ‹æ€§ï¼ˆæ—¥å¿—/ç›‘æ§ï¼‰

---

## ğŸ“ˆ åç»­å·¥ä½œ

**å¼€å‘é˜¶æ®µï¼ˆå‚è€ƒPRDï¼‰ï¼š**

1. **Week 1-2: åŸºç¡€æ¡†æ¶**
   - Mininetå®éªŒç®¡ç†å™¨
   - æµé‡æ•è·å™¨
   - åŸºç¡€ç‰¹å¾æå–ï¼ˆ10ä¸ªæ ¸å¿ƒç‰¹å¾ï¼‰

2. **Week 3-5: æ ¸å¿ƒåŠŸèƒ½**
   - å®Œæ•´ç‰¹å¾å·¥ç¨‹ï¼ˆ35ä¸ªç‰¹å¾ï¼‰
   - å®æ—¶ç›‘æµ‹æµæ°´çº¿
   - CLIè¾“å‡º

3. **Week 6-7: æ¨¡å‹è®­ç»ƒ**
   - æ•°æ®é‡‡é›†ï¼ˆ30+åœºæ™¯ï¼‰
   - è®­ç»ƒæµæ°´çº¿
   - æ¨¡å‹è¯„ä¼°

4. **Week 8-9: é›†æˆæµ‹è¯•**
   - ç«¯åˆ°ç«¯æµ‹è¯•
   - æ€§èƒ½ä¼˜åŒ–
   - æ–‡æ¡£å®Œå–„

5. **Week 10: å‘å¸ƒ**
   - ç”¨æˆ·éªŒæ”¶
   - è®ºæ–‡å®éªŒæ”¯æŒ

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- [PRDäº§å“éœ€æ±‚æ–‡æ¡£](PRD.md)
- [å¤´è„‘é£æš´ä¼šè¯](brainstorming-session-2025-11-08.md) - ç¬¬ä¸€æ€§åŸç†ç‰¹å¾å·¥ç¨‹
- [ç»¼åˆé¢†åŸŸç ”ç©¶](research-comprehensive-2025-11-08.md) - æŠ€æœ¯è°ƒç ”

---

**æ¶æ„æ–‡æ¡£çŠ¶æ€ï¼š** âœ… å·²å®Œæˆ  
**ç‰ˆæœ¬ï¼š** 1.0  
**æ‰¹å‡†æ—¥æœŸï¼š** 2025-11-08

---

## ğŸ¯ æ¶æ„æ€»ç»“

æœ¬æ¶æ„è®¾è®¡äº†ä¸€ä¸ª**é«˜æ€§èƒ½ã€æ¨¡å—åŒ–ã€å¯æ‰©å±•**çš„è§†é¢‘è´¨é‡è¯„ä¼°ç³»ç»Ÿã€‚æ ¸å¿ƒç‰¹ç‚¹ï¼š

1. **Pipelineæ¶æ„** - æµå¼å¤„ç†ï¼Œå®æ—¶ç›‘æµ‹
2. **æ€§èƒ½ä¼˜åŒ–** - åŸç”ŸPython + numpyï¼Œæ»¡è¶³ < 10ç§’å»¶è¿Ÿ
3. **æ¨¡å—è§£è€¦** - 7å¤§æ¨¡å—ï¼Œç‹¬ç«‹å¼€å‘æµ‹è¯•
4. **ä»£ç å¤ç”¨** - ç›‘æµ‹å’Œè®­ç»ƒå…±äº«ç‰¹å¾è®¡ç®—
5. **æ‰©å±•æ€§** - æ¥å£æŠ½è±¡ï¼Œä¸ºV2é¢„ç•™æ‰©å±•ç‚¹

**æ¶æ„å·²å°±ç»ªï¼Œå¯å¼€å§‹å®æ–½å¼€å‘ï¼** ğŸš€




